{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae5bcee9-6588-4d29-bbb9-6fb351ef6630",
   "metadata": {
    "id": "ae5bcee9-6588-4d29-bbb9-6fb351ef6630"
   },
   "source": [
    "# L1 Language Models, the Chat Format and Tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c797991-8486-4d79-8c1d-5dc0c1289c2f",
   "metadata": {
    "id": "0c797991-8486-4d79-8c1d-5dc0c1289c2f"
   },
   "source": [
    "## Setup\n",
    "#### Load the API key and relevant Python libaries.\n",
    "In this course, we've provided some code that loads the OpenAI API key for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "19cd4e96",
   "metadata": {
    "height": 149,
    "id": "19cd4e96"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from mistralai import Mistral\n",
    "api_key = os.environ[\"MISTRAL_API_KEY\"]\n",
    "model = \"mistral-large-latest\"\n",
    "client = Mistral(api_key=api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47ba0938-7ca5-46c4-a9d1-b55708d4dc7c",
   "metadata": {
    "id": "47ba0938-7ca5-46c4-a9d1-b55708d4dc7c"
   },
   "source": [
    "#### helper function\n",
    "Low Temperature (e.g., 0.2): The model tends to produce more focused and deterministic output. It is more likely to choose the most probable next word based on its training data.\n",
    "\n",
    "Medium Temperature (e.g., 0.5): A balance between randomness and focus. It allows for some variability in the output, making it less predictable than low temperature but not as random as high temperature.\n",
    "\n",
    "High Temperature (e.g., 0.8 or 1.0): The output becomes more creative and diverse. The model is more likely to introduce less common words and phrases, resulting in more varied and sometimes unpredictable output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1ed96988",
   "metadata": {
    "height": 166,
    "id": "1ed96988"
   },
   "outputs": [],
   "source": [
    "def get_completionLessTemperature(prompt, model=\"mistral-large-latest\"):\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    response = client.chat.complete(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=0,\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe10a390-2461-447d-bf8b-8498db404c44",
   "metadata": {
    "id": "fe10a390-2461-447d-bf8b-8498db404c44"
   },
   "source": [
    "## Prompt the model and get a completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e1cc57b2",
   "metadata": {
    "height": 47,
    "id": "e1cc57b2"
   },
   "outputs": [],
   "source": [
    "response = get_completionLessTemperature(\"What is the capital of France?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "76774108",
   "metadata": {
    "height": 30,
    "id": "76774108",
    "outputId": "202778b4-6206-4481-9114-32b4650d87fd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The capital of France is Paris. Known for its art, culture, cuisine, and fashion, Paris is also the most populous city in France. It's home to iconic landmarks such as the Eiffel Tower, Louvre Museum, Notre-Dame Cathedral, and many others. Additionally, Paris is an important political, economic, and intellectual center of Europe.\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bcd2447c-4fb3-43c6-a07a-66fa2f12df81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_completionHighTemperature(prompt, model=\"mistral-large-latest\"):\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    response = client.chat.complete(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=1,\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8a34eef1-0b98-4811-b6da-3b8bbbe32000",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The capital of France is Paris. Known for its art, culture, cuisine, and fashion, Paris is also home to iconic landmarks such as the Eiffel Tower, the Louvre Museum, and Notre-Dame Cathedral. It is the most populous city in France and serves as the country's political, economic, and cultural center.\n"
     ]
    }
   ],
   "source": [
    "response = get_completionHighTemperature(\"What is the capital of France?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b83d4e38-3e3c-4c5a-a949-040a27f29d63",
   "metadata": {
    "id": "b83d4e38-3e3c-4c5a-a949-040a27f29d63"
   },
   "source": [
    "## \n",
    "Tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cc2d9e40",
   "metadata": {
    "height": 81,
    "id": "cc2d9e40",
    "outputId": "36dfdd49-735e-4564-e870-c0a53f105139"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure! If you take the letters in \"lollipop\" and reverse them, you get \"poppillol.\"\n"
     ]
    }
   ],
   "source": [
    "response = get_completion(\"Take the letters in lollipop \\\n",
    "and reverse them\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d2b14d0-749d-4a79-9812-7b00ace9ae6f",
   "metadata": {
    "id": "9d2b14d0-749d-4a79-9812-7b00ace9ae6f"
   },
   "source": [
    "\"lollipop\" in reverse should be \"popillol\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "37cab84f",
   "metadata": {
    "height": 64,
    "id": "37cab84f"
   },
   "outputs": [],
   "source": [
    "response = get_completion(\"\"\"Take the letters in \\\n",
    "l-o-l-l-i-p-o-p and reverse them\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1577c561",
   "metadata": {
    "height": 30,
    "id": "1577c561",
    "outputId": "71d6aec3-2be3-4be4-dae7-2f681b889b26"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'To reverse the letters in \"l-o-l-l-i-p-o-p,\" you simply write them in the opposite order:\\n\\np-o-p-i-l-l-o-l\\n\\nSo, the reversed sequence is \"p-o-p-i-l-l-o-l.\"'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8b88940-d3ab-4c00-b5c0-31531deaacbd",
   "metadata": {
    "id": "c8b88940-d3ab-4c00-b5c0-31531deaacbd"
   },
   "source": [
    "## Helper function (chat format)\n",
    "Here's the helper function we'll use in this course."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8f89efad",
   "metadata": {
    "height": 217,
    "id": "8f89efad"
   },
   "outputs": [],
   "source": [
    "def get_completion_from_messages(messages,\n",
    "                                 model=\"mistral-large-latest\",\n",
    "                                 temperature=0,\n",
    "                                 max_tokens=500):\n",
    "    response = client.chat.complete(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=temperature, # this is the degree of randomness of the model's output\n",
    "        max_tokens=max_tokens, # the maximum number of tokens the model can ouptut\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b28c3424",
   "metadata": {
    "height": 200,
    "id": "b28c3424",
    "outputId": "9301c102-cf55-417b-fdbf-9446da1e5dab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In a garden, under the sun so bright,\n",
      "There lived a carrot, oh such a sight!\n",
      "With a green top-hat, and a body so orange,\n",
      "In the earth, it hid, on its happiness, it did forage.\n",
      "\n",
      "It wiggled its root, and it danced with delight,\n",
      "For this carrot, oh, had a spirit so bright!\n",
      "With a smile so wide, and a heart full of cheer,\n",
      "It was the happiest carrot, far and near!\n"
     ]
    }
   ],
   "source": [
    "messages =  [\n",
    "{'role':'system',\n",
    " 'content':\"\"\"You are an assistant who\\\n",
    " responds in the style of Dr Seuss.\"\"\"},\n",
    "{'role':'user',\n",
    " 'content':\"\"\"write me a very short poem\\\n",
    " about a happy carrot\"\"\"},\n",
    "]\n",
    "response = get_completion_from_messages(messages, temperature=1)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "56c6978d",
   "metadata": {
    "height": 200,
    "id": "56c6978d",
    "outputId": "cde52c89-2fcd-4a03-f14f-2788a146c009"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In a lush garden, there lived a happy carrot named Carl, who loved basking in the sun and growing bigger each day, dreaming of the day he'd be part of a delicious meal, making someone as happy as he was in his patch.\n"
     ]
    }
   ],
   "source": [
    "# length\n",
    "messages =  [\n",
    "{'role':'system',\n",
    " 'content':'All your responses must be \\\n",
    "one sentence long.'},\n",
    "{'role':'user',\n",
    " 'content':'write me a story about a happy carrot'},\n",
    "]\n",
    "response = get_completion_from_messages(messages, temperature =1)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "14fd6331",
   "metadata": {
    "height": 234,
    "id": "14fd6331",
    "outputId": "08e33699-6b32-42e3-8417-181d19a70204"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the ground, where the sunbeams glowed, there lived a carrot named Carl, who happily grew, you know.\n"
     ]
    }
   ],
   "source": [
    "# combined\n",
    "messages =  [\n",
    "{'role':'system',\n",
    " 'content':\"\"\"You are an assistant who \\\n",
    "responds in the style of Dr Seuss. \\\n",
    "All your responses must be one sentence long.\"\"\"},\n",
    "{'role':'user',\n",
    " 'content':\"\"\"write me a story about a happy carrot\"\"\"},\n",
    "]\n",
    "response = get_completion_from_messages(messages,\n",
    "                                        temperature =1)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "89a70c79",
   "metadata": {
    "height": 387,
    "id": "89a70c79"
   },
   "outputs": [],
   "source": [
    "def get_completion_and_token_count(messages,\n",
    "                                   model=\"mistral-large-latest\",\n",
    "                                   temperature=0,\n",
    "                                   max_tokens=500):\n",
    "\n",
    "    response = client.chat.complete(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=temperature,\n",
    "        max_tokens=max_tokens,\n",
    "    )\n",
    "\n",
    "    content = response.choices[0].message.content\n",
    "\n",
    "    token_dict = {\n",
    "'prompt_tokens':response.usage.prompt_tokens,\n",
    "'completion_tokens':response.usage.completion_tokens,\n",
    "'total_tokens':response.usage.total_tokens,\n",
    "    }\n",
    "\n",
    "    return content, token_dict, response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a64cf3c6",
   "metadata": {
    "height": 183,
    "id": "a64cf3c6"
   },
   "outputs": [],
   "source": [
    "messages = [\n",
    "{'role':'system',\n",
    " 'content':\"\"\"You are an assistant who responds\\\n",
    " in the style of Dr Seuss.\"\"\"},\n",
    "{'role':'user',\n",
    " 'content':\"\"\"write me a very short poem \\\n",
    " about a happy carrot\"\"\"},\n",
    "]\n",
    "response, token_dict, fullResponse = get_completion_and_token_count(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "cfd8fbd4",
   "metadata": {
    "height": 30,
    "id": "cfd8fbd4",
    "outputId": "b855bd75-553d-4d49-b315-c304d89771a5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the garden, under the sun so bright,\n",
      "There lived a carrot, oh such a sight!\n",
      "With a green top-hat, and an orange suit,\n",
      "It didn't fret, or worry, or sulk or pout.\n",
      "\n",
      "It said, \"I grow in the earth, I'm not fancy or fine,\n",
      "But I'm happy just being, just carrot, just mine!\"\n",
      "So it danced in the breeze, and it swayed in the light,\n",
      "This happy carrot, oh such a sight!\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "352ad320",
   "metadata": {
    "height": 30,
    "id": "352ad320",
    "outputId": "6b50a4f1-211d-4644-fd75-32de5d016885"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'prompt_tokens': 32, 'completion_tokens': 117, 'total_tokens': 149}\n"
     ]
    }
   ],
   "source": [
    "print(token_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "cd742eb6-5bd3-4069-9084-604232651139",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id='79b55cfb717f47d9b7f1069a391600e8' object='chat.completion' model='mistral-large-latest' usage=UsageInfo(prompt_tokens=32, completion_tokens=117, total_tokens=149) created=1741017423 choices=[ChatCompletionChoice(index=0, message=AssistantMessage(content='In the garden, under the sun so bright,\\nThere lived a carrot, oh such a sight!\\nWith a green top-hat, and an orange suit,\\nIt didn\\'t fret, or worry, or sulk or pout.\\n\\nIt said, \"I grow in the earth, I\\'m not fancy or fine,\\nBut I\\'m happy just being, just carrot, just mine!\"\\nSo it danced in the breeze, and it swayed in the light,\\nThis happy carrot, oh such a sight!', tool_calls=None, prefix=False, role='assistant'), finish_reason='stop')]\n"
     ]
    }
   ],
   "source": [
    "print(fullResponse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65372cdd-d869-4768-947a-0173e7f96335",
   "metadata": {
    "id": "65372cdd-d869-4768-947a-0173e7f96335"
   },
   "source": [
    "#### Notes on using the OpenAI API outside of this classroom\n",
    "\n",
    "To install the OpenAI Python library:\n",
    "```\n",
    "!pip install openai\n",
    "```\n",
    "\n",
    "The library needs to be configured with your account's secret key, which is available on the [website](https://platform.openai.com/account/api-keys).\n",
    "\n",
    "You can either set it as the `OPENAI_API_KEY` environment variable before using the library:\n",
    " ```\n",
    " !export OPENAI_API_KEY='sk-...'\n",
    " ```\n",
    "\n",
    "Or, set `openai.api_key` to its value:\n",
    "\n",
    "```\n",
    "import openai\n",
    "openai.api_key = \"sk-...\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8f889c1-f2e4-40a5-bd27-164facb54402",
   "metadata": {
    "id": "d8f889c1-f2e4-40a5-bd27-164facb54402"
   },
   "source": [
    "#### A note about the backslash\n",
    "- In the course, we are using a backslash `\\` to make the text fit on the screen without inserting newline '\\n' characters.\n",
    "- GPT-3 isn't really affected whether you insert newline characters or not.  But when working with LLMs in general, you may consider whether newline characters in your prompt may affect the model's performance."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
